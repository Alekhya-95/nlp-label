{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the dataset using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbareddy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./NLP-Task/nlpdata.txt',sep=',,,',header=None)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Display the top 5 lines in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how did serfdom develop in and then leave russ...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what films featured the character popeye doyle ?</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how can i find a list of celebrities ' real na...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what fowl grabs the spotlight after the chines...</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the full form of .com ?</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0         1\n",
       "0  how did serfdom develop in and then leave russ...   unknown\n",
       "1  what films featured the character popeye doyle ?       what\n",
       "2  how can i find a list of celebrities ' real na...   unknown\n",
       "3  what fowl grabs the spotlight after the chines...      what\n",
       "4                   what is the full form of .com ?       what"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       how did serfdom develop in and then leave russ...\n",
      "1       what films featured the character popeye doyle ? \n",
      "2       how can i find a list of celebrities ' real na...\n",
      "3       what fowl grabs the spotlight after the chines...\n",
      "4                        what is the full form of .com ? \n",
      "5       what contemptible scoundrel stole the cork fro...\n",
      "6       what team did baseball 's st. louis browns bec...\n",
      "7                        what is the oldest profession ? \n",
      "8                               what are liver enzymes ? \n",
      "9       name the scar-faced bounty hunter of the old w...\n",
      "10                         when was ozzy osbourne born ? \n",
      "11       why do heavier objects travel downhill faster ? \n",
      "12                    who was the pride of the yankees ? \n",
      "13                                   who killed gandhi ? \n",
      "14      what is considered the costliest disaster the ...\n",
      "15      what sprawling u.s. state boasts the most airp...\n",
      "16      what did the only repealed amendment to the u....\n",
      "17      how many jews were executed in concentration c...\n",
      "18                       what is `` nine inch nails '' ? \n",
      "19                   what is an annotated bibliography ? \n",
      "20                      what is the date of boxing day ? \n",
      "21      what articles of clothing are tokens in monopo...\n",
      "22                              name 11 famous martyrs . \n",
      "23                           what 's the olympic motto ? \n",
      "24         what is the origin of the name ` scarlett ' ? \n",
      "25       what 's the second-most-used vowel in english ? \n",
      "26                 who was the inventor of silly putty ? \n",
      "27      what is the highest waterfall in the united st...\n",
      "28                  name a golf course in myrtle beach . \n",
      "29             which two states enclose chesapeake bay ? \n",
      "                              ...                        \n",
      "1453    can an extended warranty be purchased for this...\n",
      "1454                         is the freezer frost free ? \n",
      "1455              could someone give me the dimensions ? \n",
      "1456               are these drip pans dishwasher safe ? \n",
      "1457              do these cooktops require 220 outlet ? \n",
      "1458    will this work to connect a wgd9200sq0 to a wf...\n",
      "1459    does it work for whirlpool duet ht - washer/dr...\n",
      "1460    does the old stack kit fit on the new washer a...\n",
      "1461                     is this downdraft ventilation ? \n",
      "1462    does the stainless steel trim get scratched by...\n",
      "1463    would this work with the whirlpool duet sports...\n",
      "1464                                 is it made in usa ? \n",
      "1465                    is the cooking grate removable ? \n",
      "1466    can the cooking grate be removed from the ring ? \n",
      "1467                  are the last two numbers the gal ? \n",
      "1468              can you verify the dimensions for me ? \n",
      "1469             can this tank be used for black water ? \n",
      "1470                         can you use on a airplane ? \n",
      "1471                       will it fit a 10 ft. ceiling? \n",
      "1472                            are the lights dimmable? \n",
      "1473                             do you ship item to pr? \n",
      "1474                    can i just throw them in trash ? \n",
      "1475                          are they made in the usa ? \n",
      "1476    do you sell an extension kit available for 10'...\n",
      "1477                                        is it loud ? \n",
      "1478                              can it be cut to fit ? \n",
      "1479                                 can it be removed ? \n",
      "1480                           does this hose have one ? \n",
      "1481                             can i get it in india ? \n",
      "1482    would this work on a 2008 ford edge with a nak...\n",
      "Name: 0, Length: 1483, dtype: object 0            unknown\n",
      "1               what\n",
      "2            unknown\n",
      "3               what\n",
      "4               what\n",
      "5               what\n",
      "6               what\n",
      "7               what\n",
      "8               what\n",
      "9            unknown\n",
      "10              when\n",
      "11           unknown\n",
      "12               who\n",
      "13               who\n",
      "14              what\n",
      "15              what\n",
      "16              what\n",
      "17           unknown\n",
      "18              what\n",
      "19              what\n",
      "20              what\n",
      "21              what\n",
      "22           unknown\n",
      "23              what\n",
      "24              what\n",
      "25              what\n",
      "26               who\n",
      "27              what\n",
      "28           unknown\n",
      "29           unknown\n",
      "            ...     \n",
      "1453     affirmation\n",
      "1454     affirmation\n",
      "1455     affirmation\n",
      "1456     affirmation\n",
      "1457     affirmation\n",
      "1458     affirmation\n",
      "1459     affirmation\n",
      "1460     affirmation\n",
      "1461     affirmation\n",
      "1462     affirmation\n",
      "1463     affirmation\n",
      "1464     affirmation\n",
      "1465     affirmation\n",
      "1466     affirmation\n",
      "1467     affirmation\n",
      "1468     affirmation\n",
      "1469     affirmation\n",
      "1470     affirmation\n",
      "1471     affirmation\n",
      "1472     affirmation\n",
      "1473     affirmation\n",
      "1474     affirmation\n",
      "1475     affirmation\n",
      "1476     affirmation\n",
      "1477     affirmation\n",
      "1478     affirmation\n",
      "1479     affirmation\n",
      "1480     affirmation\n",
      "1481     affirmation\n",
      "1482     affirmation\n",
      "Name: 1, Length: 1483, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data[0],data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "what           609\n",
       "who            402\n",
       "unknown        272\n",
       "affirmation    104\n",
       "when            96\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove the trailing spaces in labels\n",
    "data[1] = data[1].str.strip()\n",
    "data[1].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert categorical to numerical for label column using LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "myencoder = LabelEncoder()\n",
    "y = myencoder.fit_transform(data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using BOW to convert each sentence to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['american', 'an', 'and', 'are', 'as', 'be', 'by', 'called', 'can', 'city', 'country', 'did', 'do', 'does', 'find', 'first', 'for', 'from', 'game', 'get', 'has', 'have', 'his', 'how', 'in', 'invented', 'is', 'it', 'made', 'man', 'many', 'mean', 'most', 'name', 'new', 'of', 'on', 'people', 'president', 'that', 'the', 'there', 'this', 'time', 'to', 'used', 'was', 'were', 'what', 'when', 'where', 'which', 'who', 'why', 'with', 'work', 'world', 'wrote', 'year', 'you']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=60)\n",
    "X = vectorizer.fit_transform(data[0])\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X.toarray(),y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(x_train,y_train)\n",
    "y_pred = dt_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.95      0.86        22\n",
      "          1       0.93      0.86      0.90        65\n",
      "          2       0.95      0.94      0.95       120\n",
      "          3       0.79      0.73      0.76        15\n",
      "          4       0.97      1.00      0.99        75\n",
      "\n",
      "avg / total       0.93      0.93      0.93       297\n",
      "\n",
      "[[ 21   1   0   0   0]\n",
      " [  6  56   2   1   0]\n",
      " [  0   3 113   2   2]\n",
      " [  0   0   4  11   0]\n",
      " [  0   0   0   0  75]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93979933 0.89597315 0.94594595 0.91554054 0.93537415]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(dt_model,X,y,cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(x_train,y_train)\n",
    "y_pred = lr_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.77      0.83        22\n",
      "          1       0.92      0.92      0.92        65\n",
      "          2       0.96      0.99      0.98       120\n",
      "          3       0.92      0.80      0.86        15\n",
      "          4       0.99      1.00      0.99        75\n",
      "\n",
      "avg / total       0.95      0.95      0.95       297\n",
      "\n",
      "[[ 17   5   0   0   0]\n",
      " [  2  60   2   1   0]\n",
      " [  0   0 119   0   1]\n",
      " [  0   0   3  12   0]\n",
      " [  0   0   0   0  75]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95986622 0.93959732 0.96959459 0.94594595 0.96938776]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(lr_model,X,y,cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Don't remove stopwords - because when, where, who,why,how all these words belongs to stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'it', 'mustn', \"won't\", 'does', 've', \"weren't\", 'that', 'these', 'only', 'or', \"hasn't\", 'and', 'wouldn', 'been', 'ourselves', 'themselves', 'of', 'needn', 'in', 'same', 'she', 'some', 'ma', 'yourselves', 'nor', 'myself', 'both', 'yourself', 'what', \"hadn't\", 'which', 'down', 'for', 'other', 'm', 'own', 'are', 'has', \"isn't\", 'mightn', 'll', 'further', 'under', 'so', 'before', \"you're\", 'again', 'y', 'you', \"doesn't\", \"needn't\", 'them', 'won', 'yours', 'the', 'hers', 'just', 'because', 'having', 'hasn', 'am', 'over', 'were', \"couldn't\", 'through', 'to', 'their', 'herself', 'at', 'about', \"mustn't\", 'wasn', 'this', 'isn', 'against', 'can', 'they', 'is', 'until', 'him', 'whom', 'than', 'who', 'my', 'where', 'couldn', 'did', \"you'd\", \"don't\", 'didn', 's', 'each', 'between', 'into', 'no', 'very', 'all', 'with', \"shan't\", 'why', 'any', 'me', 'haven', 'not', 'but', \"wasn't\", 'how', \"aren't\", 'being', 'out', 'then', 'too', 'few', 'have', 'from', 'off', 't', 'had', 'if', 'such', 'there', 'ours', 'i', 'after', \"should've\", 'don', \"haven't\", \"she's\", 'weren', \"mightn't\", \"you've\", 'now', 'during', 'most', 'theirs', 'once', 'o', \"didn't\", 'will', 'doing', 'ain', \"wouldn't\", 'itself', 'hadn', 'those', 'shan', 'her', 'doesn', 'himself', 'was', 'above', \"that'll\", 'on', \"it's\", 'be', 'we', 'he', 'while', \"you'll\", 'shouldn', 're', 'an', 'a', 'up', 'its', 'here', \"shouldn't\", 'below', 'his', 'when', 'd', 'more', 'should', 'aren', 'your', 'as', 'do', 'our', 'by'}\n"
     ]
    }
   ],
   "source": [
    "print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['american', 'an', 'and', 'are', 'as', 'be', 'by', 'can', 'city', 'country', 'did', 'do', 'does', 'find', 'first', 'for', 'from', 'get', 'has', 'have', 'his', 'how', 'in', 'invented', 'is', 'it', 'many', 'most', 'name', 'of', 'on', 'people', 'president', 'that', 'the', 'there', 'this', 'to', 'was', 'were', 'what', 'when', 'where', 'which', 'who', 'with', 'work', 'world', 'wrote', 'you']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=50)\n",
    "X_tf = vectorizer.fit_transform(data[0])\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X_tf.toarray(),y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.80      0.82        25\n",
      "          1       0.78      0.84      0.81        45\n",
      "          2       0.93      0.96      0.94       121\n",
      "          3       0.91      0.69      0.78        29\n",
      "          4       1.00      1.00      1.00        77\n",
      "\n",
      "avg / total       0.91      0.91      0.91       297\n",
      "\n",
      "[[ 20   5   0   0   0]\n",
      " [  3  38   3   1   0]\n",
      " [  0   4 116   1   0]\n",
      " [  1   2   6  20   0]\n",
      " [  0   0   0   0  77]]\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(x_train,y_train)\n",
    "y_pred = dt_model.predict(x_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.80      0.87        25\n",
      "          1       0.89      0.89      0.89        45\n",
      "          2       0.90      1.00      0.95       121\n",
      "          3       1.00      0.69      0.82        29\n",
      "          4       1.00      1.00      1.00        77\n",
      "\n",
      "avg / total       0.94      0.94      0.93       297\n",
      "\n",
      "[[ 20   4   1   0   0]\n",
      " [  1  40   4   0   0]\n",
      " [  0   0 121   0   0]\n",
      " [  0   1   8  20   0]\n",
      " [  0   0   0   0  77]]\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(x_train,y_train)\n",
    "y_pred = lr_model.predict(x_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.76      0.86        25\n",
      "          1       0.87      0.87      0.87        45\n",
      "          2       0.88      0.98      0.93       121\n",
      "          3       1.00      0.66      0.79        29\n",
      "          4       0.99      1.00      0.99        77\n",
      "\n",
      "avg / total       0.93      0.92      0.92       297\n",
      "\n",
      "[[ 19   2   4   0   0]\n",
      " [  0  39   5   0   1]\n",
      " [  0   2 119   0   0]\n",
      " [  0   2   8  19   0]\n",
      " [  0   0   0   0  77]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import  KNeighborsClassifier\n",
    "knn_model = KNeighborsClassifier(metric='jaccard')\n",
    "knn_model.fit(x_train,y_train)\n",
    "y_pred = knn_model.predict(x_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
